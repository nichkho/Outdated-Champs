{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question\n",
    "We all know that new champions come with overloaded kits that old champs can't keep up with, but just how much do new champions push old champs out of the meta? Let's check the LCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join(r\"NALCS data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize dataframes\n",
    "summer_2021 = None\n",
    "spring_2021 = None\n",
    "summer_2020 = None\n",
    "spring_2020 = None\n",
    "summer_2019 = None\n",
    "spring_2019 = None\n",
    "summer_2018 = None\n",
    "spring_2018 = None\n",
    "summer_2017 = None\n",
    "spring_2017 = None\n",
    "summer_2016 = None\n",
    "spring_2016 = None\n",
    "summer_2015 = None\n",
    "spring_2015 = None\n",
    "summer_2014 = None\n",
    "spring_2014 = None\n",
    "summer_2013 = None\n",
    "spring_2013 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the files\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            if '2021' in file: \n",
    "                if 'Summer'in file:#create summer 2021 dataset\n",
    "                    if summer_2021 is None:\n",
    "                        summer_2021 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2021 = pd.merge(summer_2021, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2021 dataset\n",
    "                    if spring_2021 is None:\n",
    "                        spring_2021 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2021 = pd.merge(spring_2021, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "            if '2020' in file: \n",
    "                if 'Summer'in file:#create summer 2020 dataset\n",
    "                    if summer_2020 is None:\n",
    "                        summer_2020 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2020 = pd.merge(summer_2020, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2020 dataset\n",
    "                    if spring_2020 is None:\n",
    "                        spring_2020 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2020 = pd.merge(spring_2020, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "            \n",
    "            if '2019' in file: \n",
    "                if 'Summer'in file:#create summer 2019 dataset\n",
    "                    if summer_2019 is None:\n",
    "                        summer_2019 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2019 = pd.merge(summer_2019, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2019 dataset\n",
    "                    if spring_2019 is None:\n",
    "                        spring_2019 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2019 = pd.merge(spring_2019, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "            if '2018' in file: \n",
    "                if 'Summer'in file:#create summer 2018 dataset\n",
    "                    if summer_2018 is None:\n",
    "                        summer_2018 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2018 = pd.merge(summer_2018, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2018 dataset\n",
    "                    if spring_2018 is None:\n",
    "                        spring_2018 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2018 = pd.merge(spring_2018, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "            if '2017' in file: \n",
    "                if 'Summer'in file:#create summer 2017 dataset\n",
    "                    if summer_2017 is None:\n",
    "                        summer_2017 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2017 = pd.merge(summer_2017, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2017 dataset\n",
    "                    if spring_2017 is None:\n",
    "                        spring_2017 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2017 = pd.merge(spring_2017, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "            if '2016' in file: \n",
    "                if 'Summer'in file:#create summer 2016 dataset\n",
    "                    if summer_2016 is None:\n",
    "                        summer_2016 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2016 = pd.merge(summer_2016, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2016 dataset\n",
    "                    if spring_2016 is None:\n",
    "                        spring_2016 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2016 = pd.merge(spring_2016, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "            if '2015' in file: \n",
    "                if 'Summer'in file:#create summer 2015 dataset\n",
    "                    if summer_2015 is None:\n",
    "                        summer_2015 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2015 = pd.merge(summer_2015, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2015 dataset\n",
    "                    if spring_2015 is None:\n",
    "                        spring_2015 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2015 = pd.merge(spring_2015, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "            if '2014' in file: \n",
    "                if 'Summer'in file:#create summer 2014 dataset\n",
    "                    if summer_2014 is None:\n",
    "                        summer_2014 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2014 = pd.merge(summer_2014, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2014 dataset\n",
    "                    if spring_2014 is None:\n",
    "                        spring_2014 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2014 = pd.merge(spring_2014, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "            if '2013' in file: \n",
    "                if 'Summer'in file:#create summer 2013 dataset\n",
    "                    if summer_2013 is None:\n",
    "                        summer_2013 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2013 = pd.merge(summer_2013, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2013 dataset\n",
    "                    if spring_2013 is None:\n",
    "                        spring_2013 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2013 = pd.merge(spring_2013, temp, on = ['Champion', 'Pos'], how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Data\n",
    "for now we just want to view games played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with all dataframes\n",
    "df_ls = [summer_2021, spring_2021, summer_2020, spring_2020, summer_2019, spring_2019, summer_2018, spring_2018,summer_2017, spring_2017, summer_2016, spring_2016, summer_2015, spring_2015, summer_2014, spring_2014, summer_2013, spring_2013]\n",
    "split_names = ['summer_2021', 'spring_2021', 'summer_2020', 'spring_2020', 'summer_2019', 'spring_2019', 'summer_2018', 'spring_2018','summer_2017', 'spring_2017', 'summer_2016', 'spring_2016', 'summer_2015', 'spring_2015', 'summer_2014', 'spring_2014', 'summer_2013', 'spring_2013']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#keep only data we want such as Champion name, Games Played, and Position\n",
    "for i in df_ls:\n",
    "    col = i.columns.unique()\n",
    "    for j in col:\n",
    "        if 'GP' in j: #keep games played\n",
    "            continue\n",
    "        if 'Champion' in j: #keep champion\n",
    "            continue\n",
    "        if 'Pos' in j: #keep position\n",
    "            continue\n",
    "        else:\n",
    "            i.drop(j, axis = 1, inplace = True)\n",
    "            \n",
    "    i.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create dictionary with all games played data and the split\n",
    "dic = {}\n",
    "name_counter = 0\n",
    "champ_ls = []\n",
    "for i in df_ls: #loop through split\n",
    "    gp_ls = []\n",
    "    for j in i['Champion'].unique(): #loop through champions\n",
    "        gp_arr = []\n",
    "        for k in i.columns.unique():\n",
    "            temp = i[i['Champion'] == j][k] #get champ data no matter the role\n",
    "            if type(temp) == pd.core.series.Series: #if there is only one column with same name\n",
    "                temp = temp.unique()\n",
    "            else: #if there are multiple columns with the same name\n",
    "                temp = temp.sum().unique()\n",
    "            if type(temp[0]) == np.float64 or type(temp[0]) == np.int64: #only get the games played data\n",
    "                for l in temp:\n",
    "                    gp_arr.append(l)\n",
    "        champ_ls.append(j)\n",
    "        sum_gp = sum(gp_arr) #sum all games\n",
    "        gp_ls.append([j, sum_gp])\n",
    "        dic[split_names[name_counter]] = gp_ls\n",
    "    name_counter = name_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe with columns as splits and index and champs\n",
    "split_df = pd.DataFrame(columns = ['to_delete'], index = set(champ_ls)) #initialize dataframe\n",
    "for i in split_names:\n",
    "    temp = pd.DataFrame(data = dic[i]).rename(columns = {0:'Champion', 1:i}).set_index('Champion') #turn split dict to dataframe\n",
    "    split_df = split_df.join(temp, how = 'outer', lsuffix = '_left', rsuffix = '_right') #join dataframes\n",
    "split_df = split_df.drop(['to_delete'], axis = 1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summer_2021</th>\n",
       "      <th>spring_2021</th>\n",
       "      <th>summer_2020</th>\n",
       "      <th>spring_2020</th>\n",
       "      <th>summer_2019</th>\n",
       "      <th>spring_2019</th>\n",
       "      <th>summer_2018</th>\n",
       "      <th>spring_2018</th>\n",
       "      <th>summer_2017</th>\n",
       "      <th>spring_2017</th>\n",
       "      <th>summer_2016</th>\n",
       "      <th>spring_2016</th>\n",
       "      <th>summer_2015</th>\n",
       "      <th>spring_2015</th>\n",
       "      <th>summer_2014</th>\n",
       "      <th>spring_2014</th>\n",
       "      <th>summer_2013</th>\n",
       "      <th>spring_2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aatrox</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ahri</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Akali</th>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alistar</th>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amumu</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zed</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ziggs</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zilean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zoe</th>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zyra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         summer_2021  spring_2021  summer_2020  spring_2020  summer_2019  \\\n",
       "Aatrox           1.0         20.0         12.0         46.0         67.0   \n",
       "Ahri             0.0          5.0          0.0          0.0          3.0   \n",
       "Akali           10.0          6.0          4.0          0.0         10.0   \n",
       "Alistar          4.0         64.0          4.0          2.0          5.0   \n",
       "Amumu            0.0          0.0          0.0          0.0          0.0   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "Zed              0.0          0.0          0.0          0.0          0.0   \n",
       "Ziggs            0.0          1.0          2.0          0.0          1.0   \n",
       "Zilean           0.0          0.0          8.0          4.0          2.0   \n",
       "Zoe              5.0         15.0         27.0         18.0         33.0   \n",
       "Zyra             0.0          0.0          1.0          0.0          1.0   \n",
       "\n",
       "         spring_2019  summer_2018  spring_2018  summer_2017  spring_2017  \\\n",
       "Aatrox           8.0         32.0          0.0          0.0          0.0   \n",
       "Ahri             0.0          2.0          0.0         38.0         30.0   \n",
       "Akali           12.0         13.0          0.0          0.0          0.0   \n",
       "Alistar          8.0         44.0         28.0         24.0          1.0   \n",
       "Amumu            0.0          0.0          0.0          0.0          0.0   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "Zed              2.0          0.0          0.0          0.0         13.0   \n",
       "Ziggs            0.0          0.0          1.0          2.0         11.0   \n",
       "Zilean           8.0         15.0          5.0          1.0          1.0   \n",
       "Zoe             24.0         21.0         10.0          0.0          0.0   \n",
       "Zyra             2.0          0.0          2.0         40.0         63.0   \n",
       "\n",
       "         summer_2016  spring_2016  summer_2015  spring_2015  summer_2014  \\\n",
       "Aatrox           0.0          0.0          0.0          0.0          0.0   \n",
       "Ahri             1.0          8.0         10.0         35.0          4.0   \n",
       "Akali            0.0          0.0          0.0          0.0          2.0   \n",
       "Alistar         36.0         58.0         53.0         12.0          5.0   \n",
       "Amumu            0.0          0.0          0.0          0.0          1.0   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "Zed              0.0          9.0          3.0         44.0          7.0   \n",
       "Ziggs            3.0          0.0          7.0          4.0         28.0   \n",
       "Zilean          26.0          7.0          0.0          2.0         10.0   \n",
       "Zoe              0.0          0.0          0.0          0.0          0.0   \n",
       "Zyra            29.0          0.0          0.0          0.0         14.0   \n",
       "\n",
       "         spring_2014  summer_2013  spring_2013  \n",
       "Aatrox           6.0          3.0          0.0  \n",
       "Ahri            28.0         35.0          5.0  \n",
       "Akali            7.0          0.0          7.0  \n",
       "Alistar          8.0          3.0         27.0  \n",
       "Amumu            1.0          5.0          9.0  \n",
       "...              ...          ...          ...  \n",
       "Zed             22.0         52.0         13.0  \n",
       "Ziggs           45.0          1.0          1.0  \n",
       "Zilean           0.0          1.0          0.0  \n",
       "Zoe              0.0          0.0          0.0  \n",
       "Zyra            14.0         56.0         10.0  \n",
       "\n",
       "[155 rows x 18 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df.to_csv(r\"C:\\Users\\Nicholas Kho\\Documents\\GitHub\\Outdated-Champs\\cleaned_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscrape to get years Champions were made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://leagueoflegends.fandom.com/wiki/List_of_champions'\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "champ_set = set(champ_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_soup = soup.find_all('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_ls = []\n",
    "for i in td_soup:\n",
    "    if '20' in i.text:\n",
    "        if 'V' in i.text:\n",
    "            continue\n",
    "        else:\n",
    "            year = i.text[:4]\n",
    "        date_ls.append(int(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>to_delete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cassiopeia</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kog'Maw</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zoe</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sejuani</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiora</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bard</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ornn</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amumu</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pantheon</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irelia</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           to_delete\n",
       "Cassiopeia       NaN\n",
       "Kog'Maw          NaN\n",
       "Zoe              NaN\n",
       "Sejuani          NaN\n",
       "Fiora            NaN\n",
       "...              ...\n",
       "Bard             NaN\n",
       "Ornn             NaN\n",
       "Amumu            NaN\n",
       "Pantheon         NaN\n",
       "Irelia           NaN\n",
       "\n",
       "[155 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(columns = ['to_delete'], index = set(champ_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Aatrox',\n",
       " 'Ahri',\n",
       " 'Akali',\n",
       " 'Alistar',\n",
       " 'Amumu',\n",
       " 'Anivia',\n",
       " 'Annie',\n",
       " 'Aphelios',\n",
       " 'Ashe',\n",
       " 'Aurelion Sol',\n",
       " 'Azir',\n",
       " 'Bard',\n",
       " 'Blitzcrank',\n",
       " 'Brand',\n",
       " 'Braum',\n",
       " 'Caitlyn',\n",
       " 'Camille',\n",
       " 'Cassiopeia',\n",
       " \"Cho'Gath\",\n",
       " 'Corki',\n",
       " 'Darius',\n",
       " 'Diana',\n",
       " 'Dr. Mundo',\n",
       " 'Draven',\n",
       " 'Ekko',\n",
       " 'Elise',\n",
       " 'Evelynn',\n",
       " 'Ezreal',\n",
       " 'Fiddlesticks',\n",
       " 'Fiora',\n",
       " 'Fizz',\n",
       " 'Galio',\n",
       " 'Gangplank',\n",
       " 'Garen',\n",
       " 'Gnar',\n",
       " 'Gragas',\n",
       " 'Graves',\n",
       " 'Gwen',\n",
       " 'Hecarim',\n",
       " 'Heimerdinger',\n",
       " 'Illaoi',\n",
       " 'Irelia',\n",
       " 'Ivern',\n",
       " 'Janna',\n",
       " 'Jarvan IV',\n",
       " 'Jax',\n",
       " 'Jayce',\n",
       " 'Jhin',\n",
       " 'Jinx',\n",
       " \"Kai'Sa\",\n",
       " 'Kalista',\n",
       " 'Karma',\n",
       " 'Karthus',\n",
       " 'Kassadin',\n",
       " 'Katarina',\n",
       " 'Kayle',\n",
       " 'Kayn',\n",
       " 'Kennen',\n",
       " \"Kha'Zix\",\n",
       " 'Kindred',\n",
       " 'Kled',\n",
       " \"Kog'Maw\",\n",
       " 'LeBlanc',\n",
       " 'Lee Sin',\n",
       " 'Leona',\n",
       " 'Lillia',\n",
       " 'Lissandra',\n",
       " 'Lucian',\n",
       " 'Lulu',\n",
       " 'Lux',\n",
       " 'Malphite',\n",
       " 'Malzahar',\n",
       " 'Maokai',\n",
       " 'Master Yi',\n",
       " 'Miss Fortune',\n",
       " 'Mordekaiser',\n",
       " 'Morgana',\n",
       " 'Nami',\n",
       " 'Nasus',\n",
       " 'Nautilus',\n",
       " 'Neeko',\n",
       " 'Nidalee',\n",
       " 'Nocturne',\n",
       " 'Nunu & Willump',\n",
       " 'Olaf',\n",
       " 'Orianna',\n",
       " 'Ornn',\n",
       " 'Pantheon',\n",
       " 'Poppy',\n",
       " 'Pyke',\n",
       " 'Qiyana',\n",
       " 'Quinn',\n",
       " 'Rakan',\n",
       " 'Rammus',\n",
       " \"Rek'Sai\",\n",
       " 'Rell',\n",
       " 'Renekton',\n",
       " 'Rengar',\n",
       " 'Riven',\n",
       " 'Rumble',\n",
       " 'Ryze',\n",
       " 'Samira',\n",
       " 'Sejuani',\n",
       " 'Senna',\n",
       " 'Seraphine',\n",
       " 'Sett',\n",
       " 'Shaco',\n",
       " 'Shen',\n",
       " 'Shyvana',\n",
       " 'Singed',\n",
       " 'Sion',\n",
       " 'Sivir',\n",
       " 'Skarner',\n",
       " 'Sona',\n",
       " 'Soraka',\n",
       " 'Swain',\n",
       " 'Sylas',\n",
       " 'Syndra',\n",
       " 'Tahm Kench',\n",
       " 'Taliyah',\n",
       " 'Talon',\n",
       " 'Taric',\n",
       " 'Teemo',\n",
       " 'Thresh',\n",
       " 'Tristana',\n",
       " 'Trundle',\n",
       " 'Tryndamere',\n",
       " 'Twisted Fate',\n",
       " 'Twitch',\n",
       " 'Udyr',\n",
       " 'Urgot',\n",
       " 'Varus',\n",
       " 'Vayne',\n",
       " 'Veigar',\n",
       " \"Vel'Koz\",\n",
       " 'Vi',\n",
       " 'Viego',\n",
       " 'Viktor',\n",
       " 'Vladimir',\n",
       " 'Volibear',\n",
       " 'Warwick',\n",
       " 'Wukong',\n",
       " 'Xayah',\n",
       " 'Xerath',\n",
       " 'Xin Zhao',\n",
       " 'Yasuo',\n",
       " 'Yone',\n",
       " 'Yorick',\n",
       " 'Yuumi',\n",
       " 'Zac',\n",
       " 'Zed',\n",
       " 'Ziggs',\n",
       " 'Zilean',\n",
       " 'Zoe',\n",
       " 'Zyra'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "champ_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
