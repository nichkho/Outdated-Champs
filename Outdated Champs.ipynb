{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question\n",
    "We all know that new champions come with overloaded kits that old champs can't keep up with, but just how much do new champions push old champs out of the meta? Let's check the LCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join(r\"C:\\Users\\Nicko\\data\\NALCS data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize dataframes\n",
    "summer_2021 = None\n",
    "spring_2021 = None\n",
    "summer_2020 = None\n",
    "spring_2020 = None\n",
    "summer_2019 = None\n",
    "spring_2019 = None\n",
    "summer_2018 = None\n",
    "spring_2018 = None\n",
    "summer_2017 = None\n",
    "spring_2017 = None\n",
    "summer_2016 = None\n",
    "spring_2016 = None\n",
    "summer_2015 = None\n",
    "spring_2015 = None\n",
    "summer_2014 = None\n",
    "spring_2014 = None\n",
    "summer_2013 = None\n",
    "spring_2013 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the files\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            if '2021' in file: \n",
    "                if 'Summer'in file:#create summer 2021 dataset\n",
    "                    if summer_2021 is None:\n",
    "                        summer_2021 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2021 = pd.merge(summer_2021, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2021 dataset\n",
    "                    if spring_2021 is None:\n",
    "                        spring_2021 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2021 = pd.merge(spring_2021, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "            if '2020' in file: \n",
    "                if 'Summer'in file:#create summer 2020 dataset\n",
    "                    if summer_2020 is None:\n",
    "                        summer_2020 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2020 = pd.merge(summer_2020, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2020 dataset\n",
    "                    if spring_2020 is None:\n",
    "                        spring_2020 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2020 = pd.merge(spring_2020, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "            \n",
    "            if '2019' in file: \n",
    "                if 'Summer'in file:#create summer 2019 dataset\n",
    "                    if summer_2019 is None:\n",
    "                        summer_2019 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2019 = pd.merge(summer_2019, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2019 dataset\n",
    "                    if spring_2019 is None:\n",
    "                        spring_2019 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2019 = pd.merge(spring_2019, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "            if '2018' in file: \n",
    "                if 'Summer'in file:#create summer 2018 dataset\n",
    "                    if summer_2018 is None:\n",
    "                        summer_2018 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2018 = pd.merge(summer_2018, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2018 dataset\n",
    "                    if spring_2018 is None:\n",
    "                        spring_2018 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2018 = pd.merge(spring_2018, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "            if '2017' in file: \n",
    "                if 'Summer'in file:#create summer 2017 dataset\n",
    "                    if summer_2017 is None:\n",
    "                        summer_2017 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2017 = pd.merge(summer_2017, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2017 dataset\n",
    "                    if spring_2017 is None:\n",
    "                        spring_2017 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2017 = pd.merge(spring_2017, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "            if '2016' in file: \n",
    "                if 'Summer'in file:#create summer 2016 dataset\n",
    "                    if summer_2016 is None:\n",
    "                        summer_2016 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2016 = pd.merge(summer_2016, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2016 dataset\n",
    "                    if spring_2016 is None:\n",
    "                        spring_2016 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2016 = pd.merge(spring_2016, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "            if '2015' in file: \n",
    "                if 'Summer'in file:#create summer 2015 dataset\n",
    "                    if summer_2015 is None:\n",
    "                        summer_2015 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2015 = pd.merge(summer_2015, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2015 dataset\n",
    "                    if spring_2015 is None:\n",
    "                        spring_2015 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2015 = pd.merge(spring_2015, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "            if '2014' in file: \n",
    "                if 'Summer'in file:#create summer 2014 dataset\n",
    "                    if summer_2014 is None:\n",
    "                        summer_2014 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2014 = pd.merge(summer_2014, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2014 dataset\n",
    "                    if spring_2014 is None:\n",
    "                        spring_2014 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2014 = pd.merge(spring_2014, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "            if '2013' in file: \n",
    "                if 'Summer'in file:#create summer 2013 dataset\n",
    "                    if summer_2013 is None:\n",
    "                        summer_2013 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2013 = pd.merge(summer_2013, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2013 dataset\n",
    "                    if spring_2013 is None:\n",
    "                        spring_2013 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2013 = pd.merge(spring_2013, temp, on = ['Champion', 'Pos'], how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Data\n",
    "for now we just want to view games played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with all dataframes\n",
    "df_ls = [summer_2021, spring_2021, summer_2020, spring_2020, summer_2019, spring_2019, summer_2018, spring_2018,summer_2017, spring_2017, summer_2016, spring_2016, summer_2015, spring_2015, summer_2014, spring_2014, summer_2013, spring_2013]\n",
    "split_names = ['summer_2021', 'spring_2021', 'summer_2020', 'spring_2020', 'summer_2019', 'spring_2019', 'summer_2018', 'spring_2018','summer_2017', 'spring_2017', 'summer_2016', 'spring_2016', 'summer_2015', 'spring_2015', 'summer_2014', 'spring_2014', 'summer_2013', 'spring_2013']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#keep only data we want such as Champion name, Games Played, and Position\n",
    "for i in df_ls:\n",
    "    col = i.columns.unique()\n",
    "    for j in col:\n",
    "        if 'GP' in j: #keep games played\n",
    "            continue\n",
    "        if 'Champion' in j: #keep champion\n",
    "            continue\n",
    "        if 'Pos' in j: #keep position\n",
    "            continue\n",
    "        else:\n",
    "            i.drop(j, axis = 1, inplace = True)\n",
    "            \n",
    "    i.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create dictionary with all games played data and the split\n",
    "dic = {}\n",
    "name_counter = 0\n",
    "champ_ls = []\n",
    "for i in df_ls: #loop through split\n",
    "    gp_ls = []\n",
    "    for j in i['Champion'].unique(): #loop through champions\n",
    "        gp_arr = []\n",
    "        for k in i.columns.unique():\n",
    "            temp = i[i['Champion'] == j][k] #get champ data no matter the role\n",
    "            if type(temp) == pd.core.series.Series: #if there is only one column with same name\n",
    "                temp = temp.unique()\n",
    "            else: #if there are multiple columns with the same name\n",
    "                temp = temp.sum().unique()\n",
    "            if type(temp[0]) == np.float64 or type(temp[0]) == np.int64: #only get the games played data\n",
    "                for l in temp:\n",
    "                    gp_arr.append(l)\n",
    "        champ_ls.append(j)\n",
    "        sum_gp = sum(gp_arr) #sum all games\n",
    "        gp_ls.append([j, sum_gp])\n",
    "        dic[split_names[name_counter]] = gp_ls\n",
    "    name_counter = name_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe with columns as splits and index and champs\n",
    "split_df = pd.DataFrame(columns = ['to_delete'], index = set(champ_ls)) #initialize dataframe\n",
    "for i in split_names:\n",
    "    temp = pd.DataFrame(data = dic[i]).rename(columns = {0:'Champion', 1:i}).set_index('Champion') #turn split dict to dataframe\n",
    "    split_df = split_df.join(temp, how = 'outer', lsuffix = '_left', rsuffix = '_right') #join dataframes\n",
    "split_df = split_df.drop(['to_delete'], axis = 1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summer_2021</th>\n",
       "      <th>spring_2021</th>\n",
       "      <th>summer_2020</th>\n",
       "      <th>spring_2020</th>\n",
       "      <th>summer_2019</th>\n",
       "      <th>spring_2019</th>\n",
       "      <th>summer_2018</th>\n",
       "      <th>spring_2018</th>\n",
       "      <th>summer_2017</th>\n",
       "      <th>spring_2017</th>\n",
       "      <th>summer_2016</th>\n",
       "      <th>spring_2016</th>\n",
       "      <th>summer_2015</th>\n",
       "      <th>spring_2015</th>\n",
       "      <th>summer_2014</th>\n",
       "      <th>spring_2014</th>\n",
       "      <th>summer_2013</th>\n",
       "      <th>spring_2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aatrox</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ahri</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Akali</th>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alistar</th>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amumu</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zed</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ziggs</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zilean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zoe</th>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zyra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         summer_2021  spring_2021  summer_2020  spring_2020  summer_2019  \\\n",
       "Aatrox           1.0         20.0         12.0         46.0         67.0   \n",
       "Ahri             0.0          5.0          0.0          0.0          3.0   \n",
       "Akali           10.0          6.0          4.0          0.0         10.0   \n",
       "Alistar          4.0         64.0          4.0          2.0          5.0   \n",
       "Amumu            0.0          0.0          0.0          0.0          0.0   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "Zed              0.0          0.0          0.0          0.0          0.0   \n",
       "Ziggs            0.0          1.0          2.0          0.0          1.0   \n",
       "Zilean           0.0          0.0          8.0          4.0          2.0   \n",
       "Zoe              5.0         15.0         27.0         18.0         33.0   \n",
       "Zyra             0.0          0.0          1.0          0.0          1.0   \n",
       "\n",
       "         spring_2019  summer_2018  spring_2018  summer_2017  spring_2017  \\\n",
       "Aatrox           8.0         32.0          0.0          0.0          0.0   \n",
       "Ahri             0.0          2.0          0.0         38.0         30.0   \n",
       "Akali           12.0         13.0          0.0          0.0          0.0   \n",
       "Alistar          8.0         44.0         28.0         24.0          1.0   \n",
       "Amumu            0.0          0.0          0.0          0.0          0.0   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "Zed              2.0          0.0          0.0          0.0         13.0   \n",
       "Ziggs            0.0          0.0          1.0          2.0         11.0   \n",
       "Zilean           8.0         15.0          5.0          1.0          1.0   \n",
       "Zoe             24.0         21.0         10.0          0.0          0.0   \n",
       "Zyra             2.0          0.0          2.0         40.0         63.0   \n",
       "\n",
       "         summer_2016  spring_2016  summer_2015  spring_2015  summer_2014  \\\n",
       "Aatrox           0.0          0.0          0.0          0.0          0.0   \n",
       "Ahri             1.0          8.0         10.0         35.0          4.0   \n",
       "Akali            0.0          0.0          0.0          0.0          2.0   \n",
       "Alistar         36.0         58.0         53.0         12.0          5.0   \n",
       "Amumu            0.0          0.0          0.0          0.0          1.0   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "Zed              0.0          9.0          3.0         44.0          7.0   \n",
       "Ziggs            3.0          0.0          7.0          4.0         28.0   \n",
       "Zilean          26.0          7.0          0.0          2.0         10.0   \n",
       "Zoe              0.0          0.0          0.0          0.0          0.0   \n",
       "Zyra            29.0          0.0          0.0          0.0         14.0   \n",
       "\n",
       "         spring_2014  summer_2013  spring_2013  \n",
       "Aatrox           6.0          3.0          0.0  \n",
       "Ahri            28.0         35.0          5.0  \n",
       "Akali            7.0          0.0          7.0  \n",
       "Alistar          8.0          3.0         27.0  \n",
       "Amumu            1.0          5.0          9.0  \n",
       "...              ...          ...          ...  \n",
       "Zed             22.0         52.0         13.0  \n",
       "Ziggs           45.0          1.0          1.0  \n",
       "Zilean           0.0          1.0          0.0  \n",
       "Zoe              0.0          0.0          0.0  \n",
       "Zyra            14.0         56.0         10.0  \n",
       "\n",
       "[155 rows x 18 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sona         68.0\n",
       "Jarvan IV    62.0\n",
       "Lulu         50.0\n",
       "Caitlyn      49.0\n",
       "Nasus        45.0\n",
       "Name: spring_2013, dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df['spring_2013'].sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thresh    96.0\n",
       "Sona      84.0\n",
       "Elise     83.0\n",
       "Zac       75.0\n",
       "Ezreal    65.0\n",
       "Name: summer_2013, dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df['summer_2013'].sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
