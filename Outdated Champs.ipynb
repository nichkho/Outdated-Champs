{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question\n",
    "We all know that new champions come with overloaded kits that old champs can't keep up with, but just how much do new champions push old champs out of the meta? Let's check the LCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join(r\"NALCS data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize dataframes\n",
    "summer_2021 = None\n",
    "spring_2021 = None\n",
    "summer_2020 = None\n",
    "spring_2020 = None\n",
    "summer_2019 = None\n",
    "spring_2019 = None\n",
    "summer_2018 = None\n",
    "spring_2018 = None\n",
    "summer_2017 = None\n",
    "spring_2017 = None\n",
    "summer_2016 = None\n",
    "spring_2016 = None\n",
    "summer_2015 = None\n",
    "spring_2015 = None\n",
    "summer_2014 = None\n",
    "spring_2014 = None\n",
    "summer_2013 = None\n",
    "spring_2013 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the files\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            if '2021' in file: \n",
    "                if 'Summer'in file:#create summer 2021 dataset\n",
    "                    if summer_2021 is None:\n",
    "                        summer_2021 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2021 = pd.merge(summer_2021, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2021 dataset\n",
    "                    if spring_2021 is None:\n",
    "                        spring_2021 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2021 = pd.merge(spring_2021, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "            if '2020' in file: \n",
    "                if 'Summer'in file:#create summer 2020 dataset\n",
    "                    if summer_2020 is None:\n",
    "                        summer_2020 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2020 = pd.merge(summer_2020, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2020 dataset\n",
    "                    if spring_2020 is None:\n",
    "                        spring_2020 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2020 = pd.merge(spring_2020, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "            \n",
    "            if '2019' in file: \n",
    "                if 'Summer'in file:#create summer 2019 dataset\n",
    "                    if summer_2019 is None:\n",
    "                        summer_2019 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2019 = pd.merge(summer_2019, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2019 dataset\n",
    "                    if spring_2019 is None:\n",
    "                        spring_2019 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2019 = pd.merge(spring_2019, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "            if '2018' in file: \n",
    "                if 'Summer'in file:#create summer 2018 dataset\n",
    "                    if summer_2018 is None:\n",
    "                        summer_2018 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2018 = pd.merge(summer_2018, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2018 dataset\n",
    "                    if spring_2018 is None:\n",
    "                        spring_2018 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2018 = pd.merge(spring_2018, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "            if '2017' in file: \n",
    "                if 'Summer'in file:#create summer 2017 dataset\n",
    "                    if summer_2017 is None:\n",
    "                        summer_2017 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2017 = pd.merge(summer_2017, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2017 dataset\n",
    "                    if spring_2017 is None:\n",
    "                        spring_2017 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2017 = pd.merge(spring_2017, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "            if '2016' in file: \n",
    "                if 'Summer'in file:#create summer 2016 dataset\n",
    "                    if summer_2016 is None:\n",
    "                        summer_2016 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2016 = pd.merge(summer_2016, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2016 dataset\n",
    "                    if spring_2016 is None:\n",
    "                        spring_2016 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2016 = pd.merge(spring_2016, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "            if '2015' in file: \n",
    "                if 'Summer'in file:#create summer 2015 dataset\n",
    "                    if summer_2015 is None:\n",
    "                        summer_2015 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2015 = pd.merge(summer_2015, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2015 dataset\n",
    "                    if spring_2015 is None:\n",
    "                        spring_2015 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2015 = pd.merge(spring_2015, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "            if '2014' in file: \n",
    "                if 'Summer'in file:#create summer 2014 dataset\n",
    "                    if summer_2014 is None:\n",
    "                        summer_2014 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2014 = pd.merge(summer_2014, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2014 dataset\n",
    "                    if spring_2014 is None:\n",
    "                        spring_2014 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2014 = pd.merge(spring_2014, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "            if '2013' in file: \n",
    "                if 'Summer'in file:#create summer 2013 dataset\n",
    "                    if summer_2013 is None:\n",
    "                        summer_2013 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        summer_2013 = pd.merge(summer_2013, temp, on = ['Champion', 'Pos'], how = 'outer')\n",
    "                        \n",
    "                if 'Spring'in file: #create spring 2013 dataset\n",
    "                    if spring_2013 is None:\n",
    "                        spring_2013 = pd.read_csv(directory + '/' + file)\n",
    "                    else:\n",
    "                        temp = pd.read_csv(directory + '/' + file)\n",
    "                        spring_2013 = pd.merge(spring_2013, temp, on = ['Champion', 'Pos'], how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Data\n",
    "for now we just want to view games played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with all dataframes\n",
    "df_ls = [summer_2021, spring_2021, summer_2020, spring_2020, summer_2019, spring_2019, summer_2018, spring_2018,summer_2017, spring_2017, summer_2016, spring_2016, summer_2015, spring_2015, summer_2014, spring_2014, summer_2013, spring_2013]\n",
    "split_names = ['summer_2021', 'spring_2021', 'summer_2020', 'spring_2020', 'summer_2019', 'spring_2019', 'summer_2018', 'spring_2018','summer_2017', 'spring_2017', 'summer_2016', 'spring_2016', 'summer_2015', 'spring_2015', 'summer_2014', 'spring_2014', 'summer_2013', 'spring_2013']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#keep only data we want such as Champion name, Games Played, and Position\n",
    "for i in df_ls:\n",
    "    col = i.columns.unique()\n",
    "    for j in col:\n",
    "        if 'GP' in j: #keep games played\n",
    "            continue\n",
    "        if 'Champion' in j: #keep champion\n",
    "            continue\n",
    "        if 'Pos' in j: #keep position\n",
    "            continue\n",
    "        else:\n",
    "            i.drop(j, axis = 1, inplace = True)\n",
    "            \n",
    "    i.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create dictionary with all games played data and the split\n",
    "dic = {}\n",
    "name_counter = 0\n",
    "champ_ls = []\n",
    "for i in df_ls: #loop through split\n",
    "    gp_ls = []\n",
    "    for j in i['Champion'].unique(): #loop through champions\n",
    "        gp_arr = []\n",
    "        for k in i.columns.unique():\n",
    "            temp = i[i['Champion'] == j][k] #get champ data no matter the role\n",
    "            if type(temp) == pd.core.series.Series: #if there is only one column with same name\n",
    "                temp = temp.unique()\n",
    "            else: #if there are multiple columns with the same name\n",
    "                temp = temp.sum().unique()\n",
    "            if type(temp[0]) == np.float64 or type(temp[0]) == np.int64: #only get the games played data\n",
    "                for l in temp:\n",
    "                    gp_arr.append(l)\n",
    "        champ_ls.append(j)\n",
    "        sum_gp = sum(gp_arr) #sum all games\n",
    "        gp_ls.append([j, sum_gp])\n",
    "        dic[split_names[name_counter]] = gp_ls\n",
    "    name_counter = name_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe with columns as splits and index and champs\n",
    "split_df = pd.DataFrame(columns = ['to_delete'], index = set(champ_ls)) #initialize dataframe\n",
    "for i in split_names:\n",
    "    temp = pd.DataFrame(data = dic[i]).rename(columns = {0:'Champion', 1:i}).set_index('Champion') #turn split dict to dataframe\n",
    "    split_df = split_df.join(temp, how = 'outer', lsuffix = '_left', rsuffix = '_right') #join dataframes\n",
    "split_df = split_df.drop(['to_delete'], axis = 1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summer_2021</th>\n",
       "      <th>spring_2021</th>\n",
       "      <th>summer_2020</th>\n",
       "      <th>spring_2020</th>\n",
       "      <th>summer_2019</th>\n",
       "      <th>spring_2019</th>\n",
       "      <th>summer_2018</th>\n",
       "      <th>spring_2018</th>\n",
       "      <th>summer_2017</th>\n",
       "      <th>spring_2017</th>\n",
       "      <th>summer_2016</th>\n",
       "      <th>spring_2016</th>\n",
       "      <th>summer_2015</th>\n",
       "      <th>spring_2015</th>\n",
       "      <th>summer_2014</th>\n",
       "      <th>spring_2014</th>\n",
       "      <th>summer_2013</th>\n",
       "      <th>spring_2013</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aatrox</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ahri</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Akali</th>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alistar</th>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amumu</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         summer_2021  spring_2021  summer_2020  spring_2020  summer_2019  \\\n",
       "Aatrox           1.0         20.0         12.0         46.0         67.0   \n",
       "Ahri             0.0          5.0          0.0          0.0          3.0   \n",
       "Akali           10.0          6.0          4.0          0.0         10.0   \n",
       "Alistar          4.0         64.0          4.0          2.0          5.0   \n",
       "Amumu            0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "         spring_2019  summer_2018  spring_2018  summer_2017  spring_2017  \\\n",
       "Aatrox           8.0         32.0          0.0          0.0          0.0   \n",
       "Ahri             0.0          2.0          0.0         38.0         30.0   \n",
       "Akali           12.0         13.0          0.0          0.0          0.0   \n",
       "Alistar          8.0         44.0         28.0         24.0          1.0   \n",
       "Amumu            0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "         summer_2016  spring_2016  summer_2015  spring_2015  summer_2014  \\\n",
       "Aatrox           0.0          0.0          0.0          0.0          0.0   \n",
       "Ahri             1.0          8.0         10.0         35.0          4.0   \n",
       "Akali            0.0          0.0          0.0          0.0          2.0   \n",
       "Alistar         36.0         58.0         53.0         12.0          5.0   \n",
       "Amumu            0.0          0.0          0.0          0.0          1.0   \n",
       "\n",
       "         spring_2014  summer_2013  spring_2013  \n",
       "Aatrox           6.0          3.0          0.0  \n",
       "Ahri            28.0         35.0          5.0  \n",
       "Akali            7.0          0.0          7.0  \n",
       "Alistar          8.0          3.0         27.0  \n",
       "Amumu            1.0          5.0          9.0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df.to_csv(r\"C:\\Users\\Nicholas Kho\\Documents\\GitHub\\Outdated-Champs\\cleaned_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscrape to get years Champions were made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://leagueoflegends.fandom.com/wiki/List_of_champions'\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "champ_set = set(champ_ls)\n",
    "champ_list = sorted(list(champ_set))\n",
    "year_list = [2009, 2010, 2011, 2012, 2013,2014,2015,2016,2017,2018,2019,2020,2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_soup = soup.find_all('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_ls = []\n",
    "for i in td_soup:\n",
    "    if '20' in i.text:\n",
    "        if 'V' in i.text:\n",
    "            continue\n",
    "        else:\n",
    "            year = i.text[:4]\n",
    "        date_ls.append(int(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_dic = {}\n",
    "index = 0\n",
    "for i in date_ls:\n",
    "    if i not in date_dic:\n",
    "        date_dic[i] = [champ_list[index]]\n",
    "    else:\n",
    "        date_dic[i].append(champ_list[index])\n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in date_dic.items()]))\n",
    "years_df = years_df[year_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alistar</td>\n",
       "      <td>Akali</td>\n",
       "      <td>Ahri</td>\n",
       "      <td>Darius</td>\n",
       "      <td>Aatrox</td>\n",
       "      <td>Azir</td>\n",
       "      <td>Bard</td>\n",
       "      <td>Aurelion Sol</td>\n",
       "      <td>Kayn</td>\n",
       "      <td>Kai'Sa</td>\n",
       "      <td>Aphelios</td>\n",
       "      <td>Lillia</td>\n",
       "      <td>Gwen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amumu</td>\n",
       "      <td>Cassiopeia</td>\n",
       "      <td>Brand</td>\n",
       "      <td>Diana</td>\n",
       "      <td>Jinx</td>\n",
       "      <td>Braum</td>\n",
       "      <td>Ekko</td>\n",
       "      <td>Camille</td>\n",
       "      <td>Ornn</td>\n",
       "      <td>Neeko</td>\n",
       "      <td>Qiyana</td>\n",
       "      <td>Rell</td>\n",
       "      <td>Viego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anivia</td>\n",
       "      <td>Ezreal</td>\n",
       "      <td>Caitlyn</td>\n",
       "      <td>Draven</td>\n",
       "      <td>Lissandra</td>\n",
       "      <td>Gnar</td>\n",
       "      <td>Illaoi</td>\n",
       "      <td>Ivern</td>\n",
       "      <td>Rakan</td>\n",
       "      <td>Pyke</td>\n",
       "      <td>Senna</td>\n",
       "      <td>Samira</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Annie</td>\n",
       "      <td>Galio</td>\n",
       "      <td>Fizz</td>\n",
       "      <td>Elise</td>\n",
       "      <td>Lucian</td>\n",
       "      <td>Kalista</td>\n",
       "      <td>Kindred</td>\n",
       "      <td>Jhin</td>\n",
       "      <td>Xayah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sylas</td>\n",
       "      <td>Seraphine</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ashe</td>\n",
       "      <td>Garen</td>\n",
       "      <td>Graves</td>\n",
       "      <td>Fiora</td>\n",
       "      <td>Quinn</td>\n",
       "      <td>Rek'Sai</td>\n",
       "      <td>Tahm Kench</td>\n",
       "      <td>Kled</td>\n",
       "      <td>Zoe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yuumi</td>\n",
       "      <td>Sett</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      2009        2010     2011    2012       2013     2014        2015  \\\n",
       "0  Alistar       Akali     Ahri  Darius     Aatrox     Azir        Bard   \n",
       "1    Amumu  Cassiopeia    Brand   Diana       Jinx    Braum        Ekko   \n",
       "2   Anivia      Ezreal  Caitlyn  Draven  Lissandra     Gnar      Illaoi   \n",
       "3    Annie       Galio     Fizz   Elise     Lucian  Kalista     Kindred   \n",
       "4     Ashe       Garen   Graves   Fiora      Quinn  Rek'Sai  Tahm Kench   \n",
       "\n",
       "           2016   2017    2018      2019       2020   2021  \n",
       "0  Aurelion Sol   Kayn  Kai'Sa  Aphelios     Lillia   Gwen  \n",
       "1       Camille   Ornn   Neeko    Qiyana       Rell  Viego  \n",
       "2         Ivern  Rakan    Pyke     Senna     Samira    NaN  \n",
       "3          Jhin  Xayah     NaN     Sylas  Seraphine    NaN  \n",
       "4          Kled    Zoe     NaN     Yuumi       Sett    NaN  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_df.to_csv(r\"C:\\Users\\Nicholas Kho\\Documents\\GitHub\\Outdated-Champs\\years_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
